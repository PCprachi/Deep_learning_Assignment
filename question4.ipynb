{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "568vmG5tkVm7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import SVHN\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRe_CQg9kXWa",
        "outputId": "81d058d6-85cc-4515-e866-290102a13e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:21<00:00, 8479151.19it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:06<00:00, 10187704.88it/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the SVHN dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = SVHN(root='./data', split='train', transform=train_transform, download=True)\n",
        "test_dataset = SVHN(root='./data', split='test', transform=test_transform, download=True)\n",
        "\n",
        "# Use a subset of the dataset (25%)\n",
        "train_subset = Subset(train_dataset, range(0, len(train_dataset), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "smtADiIekdkM"
      },
      "outputs": [],
      "source": [
        "# Step 2: Preprocess the dataset\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joms-et1khYs",
        "outputId": "d1d4134f-613d-42d6-f449-5a3a7688b636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 82.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 84.3MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 98.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Choose pretrained models\n",
        "# Implement LeNet-5 manually\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "pretrained_models = {\n",
        "    'LeNet-5': LeNet5(),\n",
        "    'VGG-16': models.vgg16(pretrained=True),\n",
        "    'ResNet-18': models.resnet18(pretrained=True),\n",
        "    'ResNet-50': models.resnet50(pretrained=True),\n",
        "    'ResNet-101': models.resnet101(pretrained=True)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HGENMh1klgc",
        "outputId": "1fbf10de-e837-49d9-a212-e37bfb69718d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LeNet-5, Epoch [1/10], Loss: 2.1063, Accuracy: 24.19%\n",
            "Model: LeNet-5, Epoch [2/10], Loss: 1.7406, Accuracy: 38.49%\n",
            "Model: LeNet-5, Epoch [3/10], Loss: 1.5571, Accuracy: 46.01%\n",
            "Model: LeNet-5, Epoch [4/10], Loss: 1.4133, Accuracy: 51.76%\n",
            "Model: LeNet-5, Epoch [5/10], Loss: 1.3055, Accuracy: 55.65%\n",
            "Model: LeNet-5, Epoch [6/10], Loss: 1.2208, Accuracy: 58.09%\n",
            "Model: LeNet-5, Epoch [7/10], Loss: 1.1774, Accuracy: 60.22%\n",
            "Model: LeNet-5, Epoch [8/10], Loss: 1.1199, Accuracy: 62.22%\n",
            "Model: LeNet-5, Epoch [9/10], Loss: 1.0656, Accuracy: 64.28%\n",
            "Model: LeNet-5, Epoch [10/10], Loss: 1.0346, Accuracy: 65.32%\n",
            "Training finished for LeNet-5\n",
            "Test Accuracy for LeNet-5: 73.89%\n",
            "Performance Report for LeNet-5:\n",
            "--------------------------------------------------\n",
            "Test Accuracy: 73.89%\n",
            "Precision: 0.7313\n",
            "Recall: 0.7044\n",
            "F1-score: 0.7081\n",
            "--------------------------------------------------\n",
            "\n",
            "Model: VGG-16, Epoch [1/10], Loss: 2.6061, Accuracy: 16.25%\n",
            "Model: VGG-16, Epoch [2/10], Loss: 2.2535, Accuracy: 18.01%\n",
            "Model: VGG-16, Epoch [3/10], Loss: 2.2479, Accuracy: 18.45%\n",
            "Model: VGG-16, Epoch [4/10], Loss: 2.2459, Accuracy: 18.50%\n",
            "Model: VGG-16, Epoch [5/10], Loss: 2.2454, Accuracy: 18.58%\n",
            "Model: VGG-16, Epoch [6/10], Loss: 2.2451, Accuracy: 18.76%\n",
            "Model: VGG-16, Epoch [7/10], Loss: 2.2440, Accuracy: 18.65%\n",
            "Model: VGG-16, Epoch [8/10], Loss: 2.2438, Accuracy: 18.71%\n",
            "Model: VGG-16, Epoch [9/10], Loss: 2.2426, Accuracy: 18.77%\n",
            "Model: VGG-16, Epoch [10/10], Loss: 2.2432, Accuracy: 18.77%\n",
            "Training finished for VGG-16\n",
            "Test Accuracy for VGG-16: 19.59%\n",
            "Performance Report for VGG-16:\n",
            "--------------------------------------------------\n",
            "Test Accuracy: 19.59%\n",
            "Precision: 0.0196\n",
            "Recall: 0.1000\n",
            "F1-score: 0.0328\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: ResNet-18, Epoch [1/10], Loss: 2.0790, Accuracy: 32.37%\n",
            "Model: ResNet-18, Epoch [2/10], Loss: 1.0332, Accuracy: 65.21%\n",
            "Model: ResNet-18, Epoch [3/10], Loss: 0.7692, Accuracy: 75.12%\n",
            "Model: ResNet-18, Epoch [4/10], Loss: 0.6758, Accuracy: 78.43%\n",
            "Model: ResNet-18, Epoch [5/10], Loss: 0.6130, Accuracy: 80.96%\n",
            "Model: ResNet-18, Epoch [6/10], Loss: 0.5728, Accuracy: 81.93%\n",
            "Model: ResNet-18, Epoch [7/10], Loss: 0.6046, Accuracy: 81.11%\n",
            "Model: ResNet-18, Epoch [8/10], Loss: 0.5150, Accuracy: 84.12%\n",
            "Model: ResNet-18, Epoch [9/10], Loss: 0.4902, Accuracy: 84.48%\n",
            "Model: ResNet-18, Epoch [10/10], Loss: 0.5131, Accuracy: 84.12%\n",
            "Training finished for ResNet-18\n",
            "Test Accuracy for ResNet-18: 89.33%\n",
            "Performance Report for ResNet-18:\n",
            "--------------------------------------------------\n",
            "Test Accuracy: 89.33%\n",
            "Precision: 0.8877\n",
            "Recall: 0.8837\n",
            "F1-score: 0.8844\n",
            "--------------------------------------------------\n",
            "\n",
            "Model: ResNet-50, Epoch [1/10], Loss: 1.5572, Accuracy: 51.28%\n",
            "Model: ResNet-50, Epoch [2/10], Loss: 0.8512, Accuracy: 72.37%\n",
            "Model: ResNet-50, Epoch [3/10], Loss: 0.8846, Accuracy: 72.48%\n",
            "Model: ResNet-50, Epoch [4/10], Loss: 0.7123, Accuracy: 77.73%\n",
            "Model: ResNet-50, Epoch [5/10], Loss: 0.5992, Accuracy: 81.06%\n",
            "Model: ResNet-50, Epoch [6/10], Loss: 0.7471, Accuracy: 77.59%\n",
            "Model: ResNet-50, Epoch [7/10], Loss: 0.8166, Accuracy: 74.13%\n",
            "Model: ResNet-50, Epoch [8/10], Loss: 0.5902, Accuracy: 81.78%\n",
            "Model: ResNet-50, Epoch [9/10], Loss: 0.4953, Accuracy: 84.37%\n",
            "Model: ResNet-50, Epoch [10/10], Loss: 0.4728, Accuracy: 85.24%\n",
            "Training finished for ResNet-50\n",
            "Test Accuracy for ResNet-50: 87.86%\n",
            "Performance Report for ResNet-50:\n",
            "--------------------------------------------------\n",
            "Test Accuracy: 87.86%\n",
            "Precision: 0.8766\n",
            "Recall: 0.8702\n",
            "F1-score: 0.8714\n",
            "--------------------------------------------------\n",
            "\n",
            "Model: ResNet-101, Epoch [1/10], Loss: 1.9525, Accuracy: 38.49%\n",
            "Model: ResNet-101, Epoch [2/10], Loss: 1.1846, Accuracy: 60.59%\n",
            "Model: ResNet-101, Epoch [3/10], Loss: 1.1082, Accuracy: 62.86%\n",
            "Model: ResNet-101, Epoch [4/10], Loss: 0.7929, Accuracy: 73.54%\n",
            "Model: ResNet-101, Epoch [5/10], Loss: 0.9766, Accuracy: 68.69%\n",
            "Model: ResNet-101, Epoch [6/10], Loss: 0.9463, Accuracy: 69.13%\n",
            "Model: ResNet-101, Epoch [7/10], Loss: 0.7135, Accuracy: 77.15%\n",
            "Model: ResNet-101, Epoch [8/10], Loss: 0.7528, Accuracy: 75.95%\n",
            "Model: ResNet-101, Epoch [9/10], Loss: 0.6313, Accuracy: 79.49%\n",
            "Model: ResNet-101, Epoch [10/10], Loss: 0.5886, Accuracy: 81.22%\n",
            "Training finished for ResNet-101\n",
            "Test Accuracy for ResNet-101: 83.98%\n",
            "Performance Report for ResNet-101:\n",
            "--------------------------------------------------\n",
            "Test Accuracy: 83.98%\n",
            "Precision: 0.8353\n",
            "Recall: 0.8254\n",
            "F1-score: 0.8282\n",
            "--------------------------------------------------\n",
            "\n",
            "Output saved to model_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Load the pretrained weights for the chosen model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 5: Fine-tune the model on the SVHN dataset\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize CSV writer\n",
        "with open('model_metrics.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
        "\n",
        "    for model_name, model in pretrained_models.items():\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Training loop with data augmentation and adjusted hyperparameters\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Track the loss and accuracy\n",
        "                running_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Print statistics every epoch\n",
        "            epoch_loss = running_loss / len(train_loader.dataset)\n",
        "            epoch_acc = correct / total * 100\n",
        "\n",
        "            print(f\"Model: {model_name}, Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "        print(\"Training finished for\", model_name)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        predicted_labels = []\n",
        "        true_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                predicted_labels.extend(predicted.cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        test_accuracy = correct / total * 100\n",
        "        print(f\"Test Accuracy for {model_name}: {test_accuracy:.2f}%\")\n",
        "\n",
        "        # Calculate precision, recall, and F1-score\n",
        "        precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "        recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "        f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "        # Write to CSV\n",
        "        writer.writerow([model_name, test_accuracy, precision, recall, f1])\n",
        "\n",
        "        # Performance report\n",
        "        print(f\"Performance Report for {model_name}:\")\n",
        "        print(\"--------------------------------------------------\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-score: {f1:.4f}\")\n",
        "        print(\"--------------------------------------------------\")\n",
        "        print()\n",
        "\n",
        "print(\"Output saved to model_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVr1PDb1kqSh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}